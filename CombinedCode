# -*- coding: utf-8 -*-
"""PneumoniaDetectionCV_MaskRCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XL17-85MDDTHWb_6QYV1Ptl08cc4DbNG

# Capstone - Pneumonia Detection Challenge - Modeling using Mask RCNN

### Here are the insights from Mask R CNN model:

Results

Import Necessary Packages
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x
import tensorflow
tensorflow.__version__

!pip3 install -q pydicom 
!pip3 install -q tqdm 
!pip3 install -q imgaug

# Commented out IPython magic to ensure Python compatibility.
import os 
import sys

import random
import math
import numpy as np
import cv2
import json
import pydicom
from imgaug import augmenters as iaa
from tqdm import tqdm
import glob

import pandas as pd 
import matplotlib
import matplotlib.pyplot as plt
from tqdm import tqdm_notebook
from matplotlib.patches import Rectangle
import seaborn as sns
import pydicom as dcm
# %matplotlib inline
import cv2

import keras
import tensorflow as tf
import tensorflow.keras
from keras.models import Sequential, Model
from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization, MaxPooling2D, GlobalAveragePooling2D, ZeroPadding2D
from tensorflow.keras.applications import DenseNet201
from keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix
from keras.callbacks import ReduceLROnPlateau

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.model_selection import cross_val_score

from google.colab import drive
drive.mount('/content/drive')

ROOT_DIR = '/content/drive/MyDrive/RSNA_PneumoniaDetectionChallenge'
# Directory to save logs and trained model
MODEL_DIR = os.path.join(ROOT_DIR, 'logs')

print(ROOT_DIR)
print(MODEL_DIR)
os.chdir(ROOT_DIR)

os.chdir(ROOT_DIR)
!git clone https://github.com/matterport/Mask_RCNN.git
os.chdir('Mask_RCNN')
!python setup.py -q install

# Import Mask RCNN
sys.path.append(os.path.join(ROOT_DIR, 'Mask_RCNN'))  # To find local version of the library
from mrcnn.config import Config
from mrcnn import utils
import mrcnn.model as modellib
from mrcnn import visualize
from mrcnn.model import log

train_dicom_dir = os.path.join(ROOT_DIR, 'stage_1_train_images')
test_dicom_dir = os.path.join(ROOT_DIR, 'stage_1_test_images')

"""
Some setup functions and classes for Mask-RCNN

    dicom_fps is a list of the dicom image path and filenames
    image_annotions is a dictionary of the annotations keyed by the filenames
    parsing the dataset returns a list of the image filenames and the annotations dictionary


"""

def get_dicom_fps(dicom_dir):
    dicom_fps = glob.glob(dicom_dir+'/'+'*.dcm')
    return list(set(dicom_fps))

def parse_dataset(dicom_dir, anns): 
    image_fps = get_dicom_fps(dicom_dir)
    image_annotations = {fp: [] for fp in image_fps}
    for index, row in anns.iterrows(): 
        fp = os.path.join(dicom_dir, row['patientId']+'.dcm')
        image_annotations[fp].append(row)
    return image_fps, image_annotations

# The following parameters have been selected to reduce running time for demonstration purposes 
# These are not optimal 

class DetectorConfig(Config):
    """Configuration for training pneumonia detection on the RSNA pneumonia dataset.
    Overrides values in the base Config class.
    """
    
    # Give the configuration a recognizable name  
    NAME = 'pneumonia'
    
    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each
    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).
    GPU_COUNT = 1
    IMAGES_PER_GPU = 8 
    
    BACKBONE = 'resnet50'
    
    NUM_CLASSES = 2  # background + 1 pneumonia classes
    
    # Use small images for faster training. Set the limits of the small side
    # the large side, and that determines the image shape.
    IMAGE_MIN_DIM = 64
    IMAGE_MAX_DIM = 64
    
    RPN_ANCHOR_SCALES = (32, 64)
    
    TRAIN_ROIS_PER_IMAGE = 16
    
    MAX_GT_INSTANCES = 3
    
    DETECTION_MAX_INSTANCES = 3
    DETECTION_MIN_CONFIDENCE = 0.9
    DETECTION_NMS_THRESHOLD = 0.1
    
    RPN_TRAIN_ANCHORS_PER_IMAGE = 16
    STEPS_PER_EPOCH = 100 
    TOP_DOWN_PYRAMID_SIZE = 32
    STEPS_PER_EPOCH = 100
    
    
config = DetectorConfig()
config.display()

class DetectorDataset(utils.Dataset):
    """Dataset class for training pneumonia detection on the RSNA pneumonia dataset.
    """

    def __init__(self, image_fps, image_annotations, orig_height, orig_width):
        super().__init__(self)
        
        # Add classes
        self.add_class('pneumonia', 1, 'Lung Opacity')
   
        # add images 
        for i, fp in enumerate(image_fps):
            annotations = image_annotations[fp]
            self.add_image('pneumonia', image_id=i, path=fp, 
                           annotations=annotations, orig_height=orig_height, orig_width=orig_width)
            
    def image_reference(self, image_id):
        info = self.image_info[image_id]
        return info['path']

    def load_image(self, image_id):
        info = self.image_info[image_id]
        fp = info['path']
        ds = pydicom.read_file(fp)
        image = ds.pixel_array
        # If grayscale. Convert to RGB for consistency.
        if len(image.shape) != 3 or image.shape[2] != 3:
            image = np.stack((image,) * 3, -1)
        return image

    def load_mask(self, image_id):
        info = self.image_info[image_id]
        annotations = info['annotations']
        count = len(annotations)
        if count == 0:
            mask = np.zeros((info['orig_height'], info['orig_width'], 1), dtype=np.uint8)
            class_ids = np.zeros((1,), dtype=np.int32)
        else:
            mask = np.zeros((info['orig_height'], info['orig_width'], count), dtype=np.uint8)
            class_ids = np.zeros((count,), dtype=np.int32)
            for i, a in enumerate(annotations):
                if a['Target'] == 1:
                    x = int(a['x'])
                    y = int(a['y'])
                    w = int(a['width'])
                    h = int(a['height'])
                    mask_instance = mask[:, :, i].copy()
                    cv2.rectangle(mask_instance, (x, y), (x+w, y+h), 255, -1)
                    mask[:, :, i] = mask_instance
                    class_ids[i] = 1
        return mask.astype(np.bool), class_ids.astype(np.int32)

# training dataset
anns = pd.read_csv(os.path.join(ROOT_DIR, 'stage_1_train_labels.csv'))
anns.head(10)

image_fps, image_annotations = parse_dataset(train_dicom_dir, anns=anns)

print(len(image_fps))
image_fps[0]

print(len(image_annotations))
val = image_annotations.items()
value_iterator = iter(val)
print(next(value_iterator))

ds = pydicom.read_file(image_fps[0]) # read dicom image from filepath 
image = ds.pixel_array # get image array

# show dicom fields 
ds

# Original DICOM image size: 1024 x 1024
ORIG_SIZE = 1024

"""Split the data into training and validation datasets"""

######################################################################
# Modify this line to use more or fewer images for training/validation. 
# To use all images, do: image_fps_list = list(image_fps)
image_fps_list = list(image_fps) 
#####################################################################

# split dataset into training vs. validation dataset 
# split ratio is set to 0.9 vs. 0.1 (train vs. validation, respectively)
sorted(image_fps_list)
random.seed(42)
random.shuffle(image_fps_list)

validation_split = 0.1
split_index = int((1 - validation_split) * len(image_fps_list))

image_fps_train = image_fps_list[:split_index]
image_fps_val = image_fps_list[split_index:]

print(len(image_fps_train), len(image_fps_val))

"""Create and prepare the training dataset using the DetectorDataset class."""

# prepare the training dataset
dataset_train = DetectorDataset(image_fps_train, image_annotations, ORIG_SIZE, ORIG_SIZE)
dataset_train.prepare()

dataset_train

# prepare the validation dataset
dataset_val = DetectorDataset(image_fps_val, image_annotations, ORIG_SIZE, ORIG_SIZE)
dataset_val.prepare()

"""Display a random image with bounding boxes"""

# Load and display random samples and their bounding boxes
# Suggestion: Run this a few times to see different examples. 

image_id = random.choice(dataset_train.image_ids)
image_fp = dataset_train.image_reference(image_id)
image = dataset_train.load_image(image_id)
mask, class_ids = dataset_train.load_mask(image_id)

print(image.shape)

plt.figure(figsize=(10, 10))
plt.subplot(1, 2, 1)
plt.imshow(image[:, :, 0], cmap='gray')
plt.axis('off')

plt.subplot(1, 2, 2)
masked = np.zeros(image.shape[:2])
for i in range(mask.shape[2]):
    masked += image[:, :, 0] * mask[:, :, i]
plt.imshow(masked, cmap='gray')
plt.axis('off')

print(image_fp)
print(class_ids)

model = modellib.MaskRCNN(mode='training', config=config, model_dir=MODEL_DIR)

"""Image Augmentation. Try finetuning some variables to custom values"""

# Image augmentation 
augmentation = iaa.SomeOf((0, 1), [
    iaa.Fliplr(0.5),
    iaa.Affine(
        scale={"x": (0.8, 1.2), "y": (0.8, 1.2)},
        translate_percent={"x": (-0.2, 0.2), "y": (-0.2, 0.2)},
        rotate=(-25, 25),
        shear=(-8, 8)
    ),
    iaa.Multiply((0.9, 1.1))
])

"""
Training the model

    dataset_train and dataset_val are derived from DetectorDataset
    DetectorDataset loads images from image filenames and masks from the annotation data
    model is Mask-RCNN


"""

# Changes done in Model.py
# Change tensor_metrics to metrics (line 2199)
#!python setup.py -q install

NUM_EPOCHS = 5

# Train Mask-RCNN Model 
import warnings 
warnings.filterwarnings("ignore")
model.train(dataset_train, dataset_val, 
            learning_rate=config.LEARNING_RATE, 
            epochs=NUM_EPOCHS, 
            layers='all'
            #augmentation=augmentation
            )

# select trained model 
dir_names = next(os.walk(model.model_dir))[1]
key = config.NAME.lower()
dir_names = filter(lambda f: f.startswith(key), dir_names)
dir_names = sorted(dir_names)

if not dir_names:
    import errno
    raise FileNotFoundError(
        errno.ENOENT,
        "Could not find model directory under {}".format(self.model_dir))
    
fps = []
# Pick last directory
for d in dir_names: 
    dir_name = os.path.join(model.model_dir, d)
    # Find the last checkpoint
    checkpoints = next(os.walk(dir_name))[2]
    checkpoints = filter(lambda f: f.startswith("mask_rcnn"), checkpoints)
    checkpoints = sorted(checkpoints)
    if not checkpoints:
        print('No weight files in {}'.format(dir_name))
    else: 
      
      checkpoint = os.path.join(dir_name, checkpoints[-1])
      fps.append(checkpoint)

model_path = sorted(fps)[-1]
print('Found model {}'.format(model_path))

class InferenceConfig(DetectorConfig):
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1

inference_config = InferenceConfig()

# Recreate the model in inference mode
model = modellib.MaskRCNN(mode='inference', 
                          config=inference_config,
                          model_dir=MODEL_DIR)

# Load trained weights (fill in path to trained weights here)
assert model_path != "", "Provide path to trained weights"
print("Loading weights from ", model_path)
model.load_weights(model_path, by_name=True)

# set color for class
def get_colors_for_class_ids(class_ids):
    colors = []
    for class_id in class_ids:
        if class_id == 1:
            colors.append((.100, .904, .204))
    return colors

"""### Compare predicted box to the expected value

"""

# Show few example of ground truth vs. predictions on the validation dataset 
dataset = dataset_val
fig = plt.figure(figsize=(10, 30))

for i in range(4):

    image_id = random.choice(dataset.image_ids)
    
    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\
        modellib.load_image_gt(dataset_val, inference_config, 
                               image_id, use_mini_mask=False)
        
    plt.subplot(6, 2, 2*i + 1)
    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, 
                                dataset.class_names,
                                colors=get_colors_for_class_ids(gt_class_id), ax=fig.axes[-1])
    
    plt.subplot(6, 2, 2*i + 2)
    results = model.detect([original_image]) #, verbose=1)
    r = results[0]
    visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], 
                                dataset.class_names, r['scores'], 
                                colors=get_colors_for_class_ids(r['class_ids']), ax=fig.axes[-1])

"""### Predictions on the Validation Set"""

# Make predictions on test images, write out sample submission 
def predict(image_fps, filepath='output_94pc.csv', min_conf=0.94): 
    
    # assume square image
    
    with open(filepath, 'w') as file:
      for image_id in tqdm(image_fps): 
        ds = pydicom.read_file(image_id)
        image = ds.pixel_array
          
        # If grayscale. Convert to RGB for consistency.
        if len(image.shape) != 3 or image.shape[2] != 3:
            image = np.stack((image,) * 3, -1) 
            
        patient_id = os.path.splitext(os.path.basename(image_id))[0]

        results = model.detect([image])
        
        r = results[0]
        #print(r)

        out_str = ""
        out_str += patient_id 
        assert( len(r['rois']) == len(r['class_ids']) == len(r['scores']) )
        
        flags = 0

        if len(r['rois']) == 0: 
            out_str += ",Not,0"                    
        else: 
            num_instances = len(r['rois'])
            out_str += ','
            for i in range(num_instances): 
                if r['scores'][i] > min_conf:
                    flags  = 1
                    
                    out_str += str(round(r['scores'][i], 2))
                    out_str += ' '

                    # x1, y1, width, height 
                    x1 = r['rois'][i][1]
                    y1 = r['rois'][i][0]
                    width = r['rois'][i][3] - x1 
                    height = r['rois'][i][2] - y1 
                    bboxes_str = "{} {} {} {}".format(x1, y1, \
                                                      width, height)    
                    out_str += bboxes_str
                
            if flags == 0:
                  out_str += "Not,0"
            else:
                  out_str += ",1"

        #print(out_str)
        file.write(out_str+"\n")

# Predict on the validation set
output_file = 'output_94pc.csv'
predict(image_fps_val, filepath=output_file)

output = pd.read_csv(output_file, names = ['patientId', 'PredString', 'Prediction'])
print(output.shape)
print(output.dtypes)
output.head()

trains = pd.read_csv('train_labels.csv')

dataval = pd.DataFrame(trains.loc[trains.patientId.isin(output.patientId), ['patientId', 'Target']])
print(dataval.shape, dataval.dtypes)
dataval.head()

dataval.drop_duplicates(keep='first',inplace=True)
print(dataval.shape)
dataval.to_csv('dataval.csv')
dataval.head()

df_merge_col = pd.merge(dataval, output, on='patientId')
df_merge_col.shape

df_merge_col.head()

df_merge.to_csv('df_merge_col.csv')

print(df_merge_col.Prediction.value_counts())
print(df_merge_col.Target.value_counts())

trueVal = []
trueVal = df_merge_col.Target.astype('int')
print(len(trueVal))
predVal = []
predVal = df_merge_col.Prediction.astype('int')
print(len(predVal))

cm_maskrcnn = confusion_matrix(y_true=trueVal, y_pred=predVal)
print(cm_maskrcnn)

print(classification_report(trueVal, predVal))

print("Accuracy using Mask RCNN on Validation set: ", round(accuracy_score(trueVal, predVal)*100,2))

"""### Predictions on the Train Set"""

# Make predictions on test images, write out sample submission 
def predict(image_fps, filepath='output.csv', min_conf=0.80): 
    
    # assume square image
    
    with open(filepath, 'w') as file:
      for image_id in tqdm(image_fps): 
        ds = pydicom.read_file(image_id)
        image = ds.pixel_array
          
        # If grayscale. Convert to RGB for consistency.
        if len(image.shape) != 3 or image.shape[2] != 3:
            image = np.stack((image,) * 3, -1) 
            
        patient_id = os.path.splitext(os.path.basename(image_id))[0]

        results = model.detect([image])
        
        r = results[0]
        #print(r)

        out_str = ""
        out_str += patient_id 
        assert( len(r['rois']) == len(r['class_ids']) == len(r['scores']) )
        
        flags = 0

        if len(r['rois']) == 0: 
            out_str += ",Not,0"                    
        else: 
            num_instances = len(r['rois'])
            out_str += ','
            for i in range(num_instances): 
                if r['scores'][i] > min_conf:
                    flags  = 1
                    
                    out_str += str(round(r['scores'][i], 2))
                    out_str += ' '

                    # x1, y1, width, height 
                    x1 = r['rois'][i][1]
                    y1 = r['rois'][i][0]
                    width = r['rois'][i][3] - x1 
                    height = r['rois'][i][2] - y1 
                    bboxes_str = "{} {} {} {}".format(x1, y1, \
                                                      width, height)    
                    out_str += bboxes_str
                
            if flags == 0:
                  out_str += "Not,0"
            else:
                  out_str += ",1"

        #print(out_str)
        file.write(out_str+"\n")

# Predict on the validation set
output_file = 'output_train.csv'
predict(image_fps_train[:5000], filepath=output_file)

output_train = pd.read_csv(output_file, names = ['patientId', 'PredString', 'Prediction'])
print(output_train.shape)
print(output_train.dtypes)
output_train.head(12)

trains = pd.read_csv('train_labels.csv')
trains.head()

dataval_train = pd.DataFrame(trains.loc[trains.patientId.isin(output_train.patientId), ['patientId', 'Target']])
dataval_train.head()

dataval_train.shape
keras.metrics.accuracy()

dataval_train = dataval_train.astype('str')
dataval_train.head()
dataval_train.drop_duplicates(keep=False,inplace=True)
print(dataval_train.shape)
dataval_train.head()

df_merge_col_train = pd.merge(output_train, dataval_train, on='patientId')

print(df_merge_col_train.shape)
df_merge_col_train.head()

df_merge_col_train.Prediction.value_counts()

df_merge_col_train.Target.value_counts()

trueVal_train = []
trueVal_train = df_merge_col_train.Target.astype('int')
len(trueVal_train)

predVal_train = []
predVal_train = df_merge_col_train.Prediction.astype('int')
len(predVal_train)

cm_maskrcnn_train = confusion_matrix(y_true=trueVal_train, y_pred=predVal_train)
print(cm_maskrcnn_train)

print(classification_report(trueVal_train, predVal_train))

print("Accuracy using Mask RCNN on Train set: ", round(accuracy_score(trueVal_train, predVal_train)*100,2))

"""Creating Submission file and finding the score"""

# Get filenames of test dataset DICOM images
test_image_fps = get_dicom_fps(test_dicom_dir)

# Make predictions on test images, write out sample submission 
def predict(image_fps, filepath='PneumoniaDetection_Submission.csv', min_conf=0.94): 
    
    # assume square image
    
    with open(filepath, 'w') as file:
      for image_id in tqdm(image_fps): 
        ds = pydicom.read_file(image_id)
        image = ds.pixel_array
          
        # If grayscale. Convert to RGB for consistency.
        if len(image.shape) != 3 or image.shape[2] != 3:
            image = np.stack((image,) * 3, -1) 
            
        patient_id = os.path.splitext(os.path.basename(image_id))[0]

        results = model.detect([image])
        r = results[0]

        out_str = ""
        out_str += patient_id 
        assert( len(r['rois']) == len(r['class_ids']) == len(r['scores']) )
        if len(r['rois']) == 0: 
            pass
        else: 
            num_instances = len(r['rois'])
            out_str += ","
            for i in range(num_instances): 
                if r['scores'][i] > min_conf: 
                    out_str += ' '
                    out_str += str(round(r['scores'][i], 2))
                    out_str += ' '

                    # x1, y1, width, height 
                    x1 = r['rois'][i][1]
                    y1 = r['rois'][i][0]
                    width = r['rois'][i][3] - x1 
                    height = r['rois'][i][2] - y1 
                    bboxes_str = "{} {} {} {}".format(x1, y1, \
                                                      width, height)    
                    out_str += bboxes_str

        file.write(out_str+"\n")

# predict only the first 3000 entries
sample_submission_fp = 'PneumoniaDetection_Submission_.94pc.csv'
predict(test_image_fps, filepath=sample_submission_fp)

"""Score on Kaggle based on this submissions file: 0.03125"""



